{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1065e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from langchain_community.document_loaders import (\n",
    "    DirectoryLoader,\n",
    "    PyPDFLoader,\n",
    "    TextLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_classic.chains import ConversationalRetrievalChain\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889aa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# Config\n",
    "# ==============================\n",
    "load_dotenv(override=True)\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "REPO_ID = \"marufmullah50/rag-vector-db\"   # NEW repo\n",
    "LOCAL_DB_PATH = \"chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715e000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 6 documents.\n",
      "Created 25 chunks.\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_3804\\1498094674.py:60: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfadcdeb8c140b6ba0b02f9c8a99528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 25 documents\n",
      "Pushing chroma_db to marufmullah50/rag-vector-db (private)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaacbc066184c76bd73b3d3d34527cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c441bf308e314cf0a78fa7e48651eab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector DB pushed successfully!\n"
     ]
    }
   ],
   "source": [
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"HF_TOKEN not found.\")\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "print(\"Loading documents...\")\n",
    "\n",
    "folders = glob.glob(\"file/*\")\n",
    "documents = []\n",
    "\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "\n",
    "    pdf_loader = DirectoryLoader(\n",
    "        folder,\n",
    "        glob=\"**/*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "\n",
    "    md_loader = DirectoryLoader(\n",
    "        folder,\n",
    "        glob=\"**/*.md\",\n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "\n",
    "    for loader in [pdf_loader, md_loader]:\n",
    "        try:\n",
    "            folder_docs = loader.load()\n",
    "            for doc in folder_docs:\n",
    "                doc.metadata[\"doc_type\"] = doc_type\n",
    "                documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping some files: {e}\")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "if not documents:\n",
    "    print(\"No documents found.\")\n",
    "    \n",
    "\n",
    "# ==============================\n",
    "# Split\n",
    "# ==============================\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks.\")\n",
    "\n",
    "# ==============================\n",
    "# Create Embeddings\n",
    "# ==============================\n",
    "print(\"Creating embeddings...\")\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(LOCAL_DB_PATH):\n",
    "    Chroma(persist_directory=LOCAL_DB_PATH, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=LOCAL_DB_PATH)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n",
    "\n",
    "# ==============================\n",
    "# Push to HF\n",
    "# ==============================\n",
    "print(f\"Pushing {LOCAL_DB_PATH} to {REPO_ID} (private)...\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.create_repo(\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type=\"model\",\n",
    "    private=True,\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=LOCAL_DB_PATH,\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "print(\"✅ Vector DB pushed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
