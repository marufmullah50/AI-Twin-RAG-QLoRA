{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip installs\n\n!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n!pip install -q --upgrade requests==2.32.3 bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 datasets==3.2.0 peft==0.14.0 trl==0.14.0 matplotlib wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nimport math\nfrom tqdm import tqdm\nfrom google.colab import userdata\nfrom huggingface_hub import login\nimport torch\nimport transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, set_seed, BitsAndBytesConfig\nfrom datasets import load_dataset, Dataset, DatasetDict\nimport wandb\nfrom peft import LoraConfig\nfrom trl import SFTTrainer, SFTConfig\nfrom datetime import datetime\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:24.130258Z","iopub.execute_input":"2026-02-16T21:13:24.130874Z","iopub.status.idle":"2026-02-16T21:13:33.279764Z","shell.execute_reply.started":"2026-02-16T21:13:24.130829Z","shell.execute_reply":"2026-02-16T21:13:33.278801Z"}},"outputs":[{"name":"stderr","text":"2026-02-16 21:13:30.627812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771276410.649726     235 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771276410.656360     235 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771276410.674282     235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771276410.674307     235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771276410.674309     235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771276410.674311     235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Constants\n\nBASE_MODEL = \"google/gemma-2-2b-it\"\nPROJECT_NAME = \"Ai-Twin\"\nHF_USER = \"marufmullah50\" \n\n# Data\n\nDATASET_NAME = f\"{HF_USER}/Ai-Twin-data\"\nMAX_SEQUENCE_LENGTH = 182\n\n# Run name for saving the model in the hub\nRUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\nPROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\nHUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n\n# Hyperparameters for QLoRA\nLORA_R = 32\nLORA_ALPHA = 64 #Because alpha = 2 x rank\nTARGET_MODULES = [\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\nLORA_DROPOUT = 0.1\nQUANT_4_BIT = True\n\n# Hyperparameters for Training\nEPOCHS = 4\nBATCH_SIZE = 4 \nGRADIENT_ACCUMULATION_STEPS = 1\nLEARNING_RATE = 1e-4\nLR_SCHEDULER_TYPE = 'cosine'\nWARMUP_RATIO = 0.03\nOPTIMIZER = \"paged_adamw_32bit\"\n\n# Admin config - note that SAVE_STEPS is how often it will upload to the hub\n# I've changed this from 5000 to 2000 so that you get more frequent saves\n\nSTEPS = 10\nSAVE_STEPS = 100\nLOG_TO_WANDB = True\n\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:33.281489Z","iopub.execute_input":"2026-02-16T21:13:33.282096Z","iopub.status.idle":"2026-02-16T21:13:33.289646Z","shell.execute_reply.started":"2026-02-16T21:13:33.282064Z","shell.execute_reply":"2026-02-16T21:13:33.288948Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"HUB_MODEL_NAME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:33.290616Z","iopub.execute_input":"2026-02-16T21:13:33.290915Z","iopub.status.idle":"2026-02-16T21:13:33.313610Z","shell.execute_reply.started":"2026-02-16T21:13:33.290885Z","shell.execute_reply":"2026-02-16T21:13:33.313015Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'marufmullah50/Ai-Twin-2026-02-16_21.13.33'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# ==============================\n# Weights & Biases and hugging face Login (Kaggle)\n# ==============================\n\nimport os\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n# Project name\nLOG_TO_WANDB = True   # or False\n\n\n\n# Get secret from Kaggle Secrets\nuser_secrets = UserSecretsClient()\nfrom huggingface_hub import login\n\nhf_token = user_secrets.get_secret('HF_TOKEN')\nlogin(token=hf_token, add_to_git_credential=True)\n\n\n\nwandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\n# Strip whitespace just in case\nwandb_api_key = wandb_api_key.strip()\n\n# Login to W&B\nwandb.login(key=wandb_api_key)\n\n# Configure project settings\nos.environ[\"WANDB_PROJECT\"] = PROJECT_NAME\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\" if LOG_TO_WANDB else \"end\"\nos.environ[\"WANDB_WATCH\"] = \"gradients\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:35.898922Z","iopub.execute_input":"2026-02-16T21:13:35.899500Z","iopub.status.idle":"2026-02-16T21:13:44.154366Z","shell.execute_reply.started":"2026-02-16T21:13:35.899468Z","shell.execute_reply":"2026-02-16T21:13:44.153733Z"}},"outputs":[{"name":"stderr","text":"Token has not been saved to git credential helper.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmd-marufmullah50\u001b[0m (\u001b[33mmd-marufmullah50-military-institute-of-science-and-techn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"dataset = load_dataset(DATASET_NAME)\ntrain = dataset['train']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:44.155545Z","iopub.execute_input":"2026-02-16T21:13:44.156069Z","iopub.status.idle":"2026-02-16T21:13:47.287909Z","shell.execute_reply.started":"2026-02-16T21:13:44.156043Z","shell.execute_reply":"2026-02-16T21:13:47.287164Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if LOG_TO_WANDB:\n  wandb.init(project=PROJECT_NAME, name=RUN_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:47.288797Z","iopub.execute_input":"2026-02-16T21:13:47.289076Z","iopub.status.idle":"2026-02-16T21:13:54.532259Z","shell.execute_reply.started":"2026-02-16T21:13:47.289051Z","shell.execute_reply":"2026-02-16T21:13:54.531686Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.25.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260216_211347-enq5w29h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin/runs/enq5w29h' target=\"_blank\">2026-02-16_21.13.33</a></strong> to <a href='https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin' target=\"_blank\">https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin/runs/enq5w29h' target=\"_blank\">https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin/runs/enq5w29h</a>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# pick the right quantization\n\nif QUANT_4_BIT:\n  quant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type=\"nf4\"\n  )\nelse:\n  quant_config = BitsAndBytesConfig(\n    load_in_8bit=True,\n    bnb_8bit_compute_dtype=torch.bfloat16\n  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:54.533593Z","iopub.execute_input":"2026-02-16T21:13:54.533895Z","iopub.status.idle":"2026-02-16T21:13:54.539763Z","shell.execute_reply.started":"2026-02-16T21:13:54.533871Z","shell.execute_reply":"2026-02-16T21:13:54.539222Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load the Tokenizer and the Model\n\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    quantization_config=quant_config,\n    device_map=\"auto\",\n)\nbase_model.generation_config.pad_token_id = tokenizer.pad_token_id\n\nprint(f\"Memory footprint: {base_model.get_memory_footprint() / 1e6:.1f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:13:54.540765Z","iopub.execute_input":"2026-02-16T21:13:54.541115Z","iopub.status.idle":"2026-02-16T21:14:02.704054Z","shell.execute_reply.started":"2026-02-16T21:13:54.541092Z","shell.execute_reply":"2026-02-16T21:14:02.703255Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34215d61a16147a29b885a5719f0cece"}},"metadata":{}},{"name":"stdout","text":"Memory footprint: 2192.3 MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"base_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:14:02.705149Z","iopub.execute_input":"2026-02-16T21:14:02.705463Z","iopub.status.idle":"2026-02-16T21:14:02.712797Z","shell.execute_reply.started":"2026-02-16T21:14:02.705429Z","shell.execute_reply":"2026-02-16T21:14:02.712146Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Gemma2ForCausalLM(\n  (model): Gemma2Model(\n    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n    (layers): ModuleList(\n      (0-25): 26 x Gemma2DecoderLayer(\n        (self_attn): Gemma2Attention(\n          (q_proj): Linear4bit(in_features=2304, out_features=2048, bias=False)\n          (k_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=2048, out_features=2304, bias=False)\n        )\n        (mlp): Gemma2MLP(\n          (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n          (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n          (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n          (act_fn): PytorchGELUTanh()\n        )\n        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n      )\n    )\n    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n    (rotary_emb): Gemma2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from trl import DataCollatorForCompletionOnlyLM\n\ndef formatting_prompts_func(example):\n    output_texts = []\n    for i in range(len(example['instruction'])):\n        messages = [\n            {\"role\": \"user\", \"content\": example['instruction'][i]},\n            {\"role\": \"model\", \"content\": example['output'][i]}\n        ]\n        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n        output_texts.append(text)\n    return output_texts\n\nresponse_template = \"<start_of_turn>model\"\ncollator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:14:02.714056Z","iopub.execute_input":"2026-02-16T21:14:02.714280Z","iopub.status.idle":"2026-02-16T21:14:02.726914Z","shell.execute_reply.started":"2026-02-16T21:14:02.714258Z","shell.execute_reply":"2026-02-16T21:14:02.726171Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# First, specify the configuration parameters for LoRA\n\nlora_parameters = LoraConfig(\n    lora_alpha=LORA_ALPHA,\n    lora_dropout=LORA_DROPOUT,\n    r=LORA_R,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=TARGET_MODULES,\n)\n\n# Next, specify the general configuration parameters for training\n\ntrain_parameters = SFTConfig(\n    output_dir=PROJECT_RUN_NAME,\n    num_train_epochs=EPOCHS,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=1,\n    eval_strategy=\"no\",\n    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n    optim=OPTIMIZER,\n    save_steps=SAVE_STEPS,\n    save_total_limit=10,\n    logging_steps=STEPS,\n    learning_rate=LEARNING_RATE,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=True,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=WARMUP_RATIO,\n    group_by_length=True,\n    lr_scheduler_type=LR_SCHEDULER_TYPE,\n    report_to=\"wandb\" if LOG_TO_WANDB else None,\n    run_name=RUN_NAME,\n    max_seq_length=MAX_SEQUENCE_LENGTH,\n    # dataset_text_field=\"text\",\n    save_strategy=\"steps\",\n    hub_strategy=\"every_save\",\n    push_to_hub=True,\n    hub_model_id=HUB_MODEL_NAME,\n    hub_private_repo=True\n)\n\n# And now, the Supervised Fine Tuning Trainer will carry out the fine-tuning\n# Given these 2 sets of configuration parameters\n# The latest version of trl is showing a warning about labels - please ignore this warning\n# But let me know if you don't see good training results (loss coming down).\n\nfine_tuning = SFTTrainer(\n    model=base_model,\n    train_dataset=train,\n    peft_config=lora_parameters,\n    args=train_parameters,\n    data_collator=collator,\n    formatting_func=formatting_prompts_func\n  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:14:07.705280Z","iopub.execute_input":"2026-02-16T21:14:07.706086Z","iopub.status.idle":"2026-02-16T21:14:10.576574Z","shell.execute_reply.started":"2026-02-16T21:14:07.706054Z","shell.execute_reply":"2026-02-16T21:14:10.575767Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Fine-tune!\nfine_tuning.train()\n\n# Push our fine-tuned model to Hugging Face\nfine_tuning.model.push_to_hub(PROJECT_RUN_NAME, private=True)\nprint(f\"Saved to the hub: {PROJECT_RUN_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:14:12.639416Z","iopub.execute_input":"2026-02-16T21:14:12.639730Z","iopub.status.idle":"2026-02-16T21:17:21.145078Z","shell.execute_reply.started":"2026-02-16T21:14:12.639703Z","shell.execute_reply":"2026-02-16T21:17:21.144485Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\nIt is strongly recommended to train Gemma2 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='148' max='148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [148/148 03:01, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>3.034000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.242700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.912100</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.621300</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.382700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.138400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.123400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.955200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.670800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.678600</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.622100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.460800</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.584600</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.570800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (Ai-Twin-2026-02-16_21.13.33/checkpoint-100)... Done. 0.4s\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (Ai-Twin-2026-02-16_21.13.33/checkpoint-148)... Done. 0.4s\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08cb48eb6a8d4c87ad657dac8241ba73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"297060d3324f41dc958b94eadad9c0af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f85b76438f406db9fe28ceb69939d3"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Saved to the hub: Ai-Twin-2026-02-16_21.13.33\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"if LOG_TO_WANDB:\n  wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T21:17:21.146262Z","iopub.execute_input":"2026-02-16T21:17:21.146511Z","iopub.status.idle":"2026-02-16T21:17:28.285976Z","shell.execute_reply.started":"2026-02-16T21:17:21.146486Z","shell.execute_reply":"2026-02-16T21:17:28.285289Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁▁▃▃▄▇▄▅▇▅█▆▅█</td></tr><tr><td>train/learning_rate</td><td>███▇▆▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▃▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>654840356663808.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>148</td></tr><tr><td>train/grad_norm</td><td>5.6112</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5708</td></tr><tr><td>train_loss</td><td>1.17097</td></tr><tr><td>train_runtime</td><td>176.1336</td></tr><tr><td>train_samples_per_second</td><td>3.338</td></tr><tr><td>train_steps_per_second</td><td>0.84</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">2026-02-16_21.13.33</strong> at: <a href='https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin/runs/enq5w29h' target=\"_blank\">https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin/runs/enq5w29h</a><br> View project at: <a href='https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin' target=\"_blank\">https://wandb.ai/md-marufmullah50-military-institute-of-science-and-techn/Ai-Twin</a><br>Synced 5 W&B file(s), 0 media file(s), 23 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260216_211347-enq5w29h/logs</code>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}